# 02 분석 변수 처리

## 1. 변수 선택

통계분석의 신뢰성을 위해서는 기본적으로 데이터와 변수가 많으면 많을수록 좋지만, 너무 많으면 분석모형을 구성하고 유지하는 데에 많은 비용이 들기 때문에, 어느정도의 설명력이 유지되는 선에서는 변수를 적게 선택하는 것이 효율적이다.

변수를 선택하는 다양한 방법들을 알아보자.

<br>

### 1) 변수별 모형의 분류

- 전체 모형(FM: Full Model): 모든 독립변수를 사용한 모형
- 축소 모형(RM: Reduced Model): 변수의 개수를 축소한 모형
- 영 모형(NM: Null Model): 독립변수가 하나도 없는 모형

<br>

### 2) 변수의 선택 방법

참고자료: https://zephyrus1111.tistory.com/65

- 전진 선택법(Forward Selection)
  - 영모형에서 시작해, 모든 독립변수 중 종속변수와 단순상관계수의 절댓값이 가장 큰 변수부터 하나씩 분석모형에 포함시킨다.
  - 부분 F검정(F test)를 통해 유의성 검증을 시행하여, 유의한 경우는 F통계량이 가장 큰 모형을 선택하고 유의하지 않은 경우 변수를 더 이상 추가하지 않고 과정을 중단.
  - 한 번 추가된 변수는 제거하지 않는다.
- 후진 선택법(Backward Selection), 후진 소거법(Backward Elimination)
  - 전체모형에서 시작해, 모든 독립변수 중 종속변수와 단순상관계수의 절댓값이 가장 작은 변수부터 하나씩 분석모형에서 제외시킨다.
  - 부분 F검정을 통해 유의성 검증을 시행하여, 유의하지 않은 경우는 변수를 제거하고 유의한 경우는 변수를 더 이상 제거하지 않고 과정을 중단.
  - 한 번 제거된 변수는 추가하지 않는다.
- 단계적 선택법(Stepwise Selection)
  - 전진 선택법과 후진 선택법의 보완방법.
  - 전진 선택법을 통해 유의한 변수들을 모형에 포함한 후, 선택된 변수들에 대해 다시 후진 선택법을 적용하여 중요하지 않은 변수를 제거하는 과정을 반복한다.
  - 더 이상 추가하거나 제거할 변수가 없을 때 종료한다.

<br><br>

## 2. 차원 축소

**차원**이란 데이터의 종류(변수)를 의미한다. 차원을 축소한다는 것은 어떤 목적에 따라서 변수의 양을 줄이는 것을 의미한다.

### 1) 차원 축소의 필요성

- 복잡도의 축소(Reduce Complexity)
  - 변수가 많아지면 분석시간의 증가(시간복잡도: Time Complexity)와 저장변수 양의 증가(공간복잡도: Space Complexity) 문제 발생
  - 동일한 품질을 나타낼 수 있다면 효율성 측면에서 차원의 수를 줄여야 한다.
- 과적합(Overfit)의 방지
  - 차원이 많아지면 분석모델의 파라미터 증가 및 파라미터간의 관계 증가로 과적합 발생의 가능성이 커진다.
  - 이는 분석모델 정확도(신뢰도) 저하로 이어진다
  - 적은 차원으로 안정적인(robust) 결과를 낼 수 있다면 많은 차원을 다루는 것보다 효율적이다
- 해석력(Interpretability)의 확보
  - 차원 수가 적은 간단한 모델일수록 해석 및 설명이 쉬워짐
- 차원의 저주(Curse of Dimensionality) 방지
  - **차원의 저주**란, **학습데이터의 수(데이터셋 개수)보다 차원의 수(변수 개수)가 많아져 성능이 저하되는 현상**을 의미
  - 차원을 줄이거나 데이터 수를 늘려야 함

<br>

### 2) 차원 축소의 방법

#### (1) **요인 분석(Factor Analysis)**

- 요인 분석의 개념

  - **변수들간의 상관관계를 분석하여 공통된 차원을 축약**하는 통계분석 과정.

- 요인분석의 목적

  - 변수 축소: 정보손실을 최대한 억제하면서 소수의 요인(Factor)으로 축약할 수 있음
  - 변수 제거: 요인에 대한 중요도를 파악할 수 있음
  - 변수 특성 파악: 서로 상관된 변수들이 묶임으로써 요인간의 상호 독립성 파악이 용이해짐

  - 타당성 평가: 다른 변수들과 묶이지 않는 변수의 독립성 여부를 판단할 수 있음
  - 파생변수: 요인점수를 이용해 새로운 변수를 생성할 수 있음

- 요인분석의 특징

  - 독립변수, 종속변수 개념이 없음. 주로 기술통계에 의한 방법을 이용

- 요인분석의 종류

  - 주성분 분석(PCA), 공통요인 분석 특이값 분해(SVD: Singular Value Decomposition) 행렬, 음수미포함 행렬분해(NMF: Non-negative Matrix Factorization) 등
    - 공통요인 분석은 분석대상 변수들의 기저를 이루는 구조를 정의하기 위한 방법으로 변수들이 가지고있는 공통분산을 이용하여 공통요인만 추출하는 방법.

#### (2) 주성분 분석(PCA)

- 주성분 분석의 개념

  - **데이터들의 특성을 설명할 수 있는 하나 이상의 특징(주성분, Principal Component)를 찾는 것.**
  - 서로 연관성이 있는 고차원공간의 데이터를 선형연관성이 없는 저차원(주성분)으로 변환. (직교변환)
  - 기존의 기본 변수들을 세로운 변수세트로 변환해 차원을 줄이되, **기존 변수들의 분포 특성을 최대한 보존**하여 이를 통한 분석결과의 신뢰성을 확보

- PCA 방법의 이해

  - 아래 데이터를 가장 잘 설명하는 두 개의 벡터는 아래 파란 선과 붉은 선이다. 두 벡터의 방향과 크기를 알면 이 데이터 분포가 어떤 형태인지를 가장 단순하면서도 효과적으로 파악할 수 있다.
  - PCA는 데이터 포인트 하나하나의 성분을 분석하는 것이 아닌, 여러 **데이터들의 분포에 대한 주성분을 분석**하는 방법이다.

  ![image](https://user-images.githubusercontent.com/44221498/140925037-63b032a2-a78d-40a2-a573-ca8daf49c608.png)

<center>이미지 출처: https://enjoyso.tistory.com/104</center>

- PCA의 특징
  - 차원축소에 폭넓게 사용됨. 어떤 **사전적 분포 가정의 요구가 없음**
  - 가장 큰 분산의 방향들이 주요 관심
  - **변수들의 선형결합**으로만 고려함
  - **본래의 변수들이 서로 상관이 있을 때만 가능**
  - 스케일 영향이 큼. 즉 PCA 수행을 위해서는 **변수들의 스케일링 작업이 필수**

